{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28292e19-a2fd-4be6-94cc-dba35406cd5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Credenciales\n",
    "sec = dbutils.secrets.get(\"scpcumpsccrit002\",\"gscp1glbsp4cumpscauth100\").split(\"[###]\")\n",
    "client_id = sec[1]\n",
    "client_secret = sec[0]\n",
    "client_endpoint = \"https://login.microsoftonline.com/35595a02-4d6d-44ac-99e1-f9ab4cd872db/oauth2/token\"\n",
    "storage_account = \"gscp1weustacumpsccrit100\"\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", client_endpoint)\n",
    "\n",
    "\n",
    "#Capturamos las variables de los widgets\n",
    "dbfs_dir = dbutils.widgets.get(\"dbfs_dir\")\n",
    "adls_output_dir = dbutils.widgets.get(\"adls_output_dir\")\n",
    "date = dbutils.widgets.get(\"date\")\n",
    "\n",
    "#Nos aseguramos que los ficheros zip y csv asociados a la fecha existen en el directorio\n",
    "required_files = {f\"report_{date}.csv\", f\"report_{date}.zip\"}\n",
    "files_in_dir = {f.name for f in dbutils.fs.ls(dbfs_dir)}\n",
    "missing = required_files - files_in_dir\n",
    "assert(missing == set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0e17561-cbd7-452a-a2c7-31ea363f9529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#Movemos el zip (descomprimido) y el csv al directorio adls_output_dir/{date}, usando directorios locales intermedios\n",
    "local_dir = dbfs_dir.replace(\"dbfs:\", \"/dbfs\")\n",
    "local_output_dir = f\"{local_dir}/output/{date}\"\n",
    "\n",
    "#Aseguramso que no haya nada en el directorio local_output_dir. Si lo hay, habr√≠a que eliminarlo, para no duplicar ficheros\n",
    "os.makedirs(local_output_dir, exist_ok=True)\n",
    "assert(not os.listdir(local_output_dir))\n",
    "\n",
    "shutil.unpack_archive(f\"{local_dir}/report_{date}.zip\", extract_dir=local_output_dir)\n",
    "shutil.move(f\"{local_dir}/report_{date}.csv\", f\"{local_output_dir}\")\n",
    "\n",
    "dbutils.fs.mv(local_output_dir.replace(\"/dbfs\", \"dbfs:\"), f\"{adls_output_dir}/{date}\", recurse=True)\n",
    "\n",
    "dbutils.fs.ls(f\"{adls_output_dir}/{date}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SWIFT_move_data_and_unzip",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}